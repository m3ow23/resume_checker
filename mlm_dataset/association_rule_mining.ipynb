{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0       date   time  ticket_number               article   \n",
      "0                0   1/2/2021   8:38         150040              baguette  \\\n",
      "1                1   1/2/2021   8:38         150040      pain au chocolat   \n",
      "2                4   1/2/2021   9:14         150041      pain au chocolat   \n",
      "3                5   1/2/2021   9:14         150041                  pain   \n",
      "4                8   1/2/2021   9:25         150042  traditional baguette   \n",
      "...            ...        ...    ...            ...                   ...   \n",
      "234000      511387  9/30/2022  18:52         288911                 coupe   \n",
      "234001      511388  9/30/2022  18:52         288911            boule 200g   \n",
      "234002      511389  9/30/2022  18:52         288911                 coupe   \n",
      "234003      511392  9/30/2022  18:55         288912  traditional baguette   \n",
      "234004      511395  9/30/2022  18:56         288913  traditional baguette   \n",
      "\n",
      "        Quantity unit_price  \n",
      "0              1     0,90 €  \n",
      "1              3     1,20 €  \n",
      "2              2     1,20 €  \n",
      "3              1     1,15 €  \n",
      "4              5     1,20 €  \n",
      "...          ...        ...  \n",
      "234000         1     0,15 €  \n",
      "234001         1     1,20 €  \n",
      "234002         2     0,15 €  \n",
      "234003         1     1,30 €  \n",
      "234004         1     1,30 €  \n",
      "\n",
      "[234005 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"french_bakery_dataset.csv\")\n",
    "\n",
    "# Data Cleaning: Remove rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "def preprocess_items(item):\n",
    "    # Convert item names to lowercase\n",
    "    item = item.lower()\n",
    "    \n",
    "    # Remove special characters (e.g., punctuations)\n",
    "    special_characters = r\"[!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\"\n",
    "    item = re.sub(special_characters, \"\", item)\n",
    "    \n",
    "    # Remove leading/trailing whitespaces\n",
    "    item = item.strip()\n",
    "    \n",
    "    return item\n",
    "\n",
    "data['article'] = data['article'].apply(preprocess_items)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticket_number\n",
      "150040                         [baguette, pain au chocolat]\n",
      "150041                             [pain au chocolat, pain]\n",
      "150042                               [traditional baguette]\n",
      "150043                                [baguette, croissant]\n",
      "150044                                            [banette]\n",
      "                                ...                        \n",
      "288908                                    [cereal baguette]\n",
      "288910                               [traditional baguette]\n",
      "288911    [campagne, traditional baguette, coupe, boule ...\n",
      "288912                               [traditional baguette]\n",
      "288913                               [traditional baguette]\n",
      "Name: article, Length: 136451, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to a transaction format where each row represents a set of items (articles) for a single transaction\n",
    "transactions = data.groupby(['ticket_number'])['article'].apply(list)\n",
    "\n",
    "print(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Item Transactions: 77797\n",
      "Multiple Item Transactions: 58654\n"
     ]
    }
   ],
   "source": [
    "singleItemTransactions = 0\n",
    "multiItemTransactions = 0\n",
    "\n",
    "# counter of single-item transactions\n",
    "for transaction in transactions:\n",
    "    if (len(transaction) == 1):\n",
    "        singleItemTransactions += 1\n",
    "    else:\n",
    "        multiItemTransactions += 1\n",
    "\n",
    "print('Single Item Transactions: ' + str(singleItemTransactions))\n",
    "print('Multiple Item Transactions: ' + str(multiItemTransactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baguette': 0, 'pain au chocolat': 1, 'pain': 2, 'traditional baguette': 3, 'croissant': 4, 'banette': 5, 'banettine': 6, 'special bread': 7, 'coupe': 8, 'sand jb emmental': 9, 'kouign amann': 10, 'boule 200g': 11, 'boule 400g': 12, 'gal frangipane 6p': 13, 'campagne': 14, 'moisson': 15, 'cafe ou eau': 16, 'brioche': 17, 'cereal baguette': 18, 'seigle': 19, 'complet': 20, 'divers patisserie': 21, 'gal frangipane 4p': 22, 'cookie': 23, 'ficelle': 24, 'pain aux raisins': 25, 'gal pomme 6p': 26, 'gal pomme 4p': 27, 'financier x5': 28, 'vik bread': 29, 'divers viennoiserie': 30, 'gache': 31, 'sandwich complet': 32, 'pain banette': 33, 'grand far breton': 34, 'quim bread': 35, 'special bread kg': 36, 'gd kouign amann': 37, 'boule polka': 38, 'demi baguette': 39, 'chausson aux pommes': 40, 'baguette graine': 41, 'divers confiserie': 42, 'sucette': 43, 'divers boulangerie': 44, 'boisson 33cl': 45, 'pates': 46, 'formule sandwich': 47, 'divers sandwichs': 48, 'croissant amandes': 49, 'pain choco amandes': 50, 'sachet viennoiserie': 51, 'nantais': 52, 'chocolat': 53, 'pain ssel': 54, 'fondant chocolat': 55, 'gal poire choco 6p': 56, 'gal poire choco 4p': 57, 'galette 8 pers': 58, 'sand jb': 59, 'sachet de crouton': 60, 'grande sucette': 61, 'demi pain': 62, 'tartelette': 63, 'flan': 64, 'paris brest': 65, 'savarin': 66, 'flan abricot': 67, 'baguette apero': 68, 'milles feuilles': 69, 'chou chantilly': 70, 'eclair': 71, 'royal 4p': 72, 'tarte fruits 6p': 73, 'tarte fruits 4p': 74, 'noix japonaise': 75, 'the': 76, 'briochette': 77, 'royal 6p': 78, 'eclair fraise pistache': 79, '': 80, 'gd far breton': 81, 'triangles': 82, 'tropezienne': 83, 'tropezienne framboise': 84, 'royal': 85, 'tarte fraise 6p': 86, 'tartelette fraise': 87, 'tarte fraise 4per': 88, 'fraisier': 89, 'nid de poule': 90, 'tartelette choc': 91, 'pain de mie': 92, 'crumble': 93, 'financier': 94, 'divers boissons': 95, 'cake': 96, 'viennoise': 97, 'traiteur': 98, 'pain graines': 99, 'platprepare650': 100, 'platprepare550': 101, 'platprepare700': 102, 'formule plat prepare': 103, 'st honore': 104, 'brownies': 105, 'religieuse': 106, 'platprepare600': 107, 'delicetropical': 108, 'crumblecaramel ou pistae': 109, 'pt nantais': 110, 'gd nantais': 111, 'douceur d hiver': 112, 'trois chocolat': 113, 'article 295': 114, 'tarte fine': 115, 'entremets': 116, 'brioche de noel': 117, 'framboisier': 118, 'buche 4pers': 119, 'buche 6pers': 120, 'gd plateau sale': 121, 'buche 8pers': 122, 'pt plateau sale': 123, 'reduction sucrees 12': 124, 'pain noir': 125, 'reduction sucrees 24': 126, 'bottereau': 127, 'meringue': 128, 'palmier': 129, 'paille': 130, 'plat 650e': 131, 'plat 760e': 132, 'plat 700': 133, 'plat': 134, 'plat 830e': 135, 'formule pate': 136, 'guerandais': 137, 'palet breton': 138, 'caramel noix': 139, 'macaron': 140, '12 macaron': 141, 'armoricain': 142, 'plaque tarte 25p': 143, 'sable f  p': 144, 'pain suisse pepito': 145, 'tulipe': 146, 'tartelette cocktail': 147, 'sachet de viennoiserie': 148}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map each unique item to a unique integer identifier\n",
    "item_to_int = {}\n",
    "for transaction in transactions:\n",
    "    for item in transaction:\n",
    "        if item not in item_to_int:\n",
    "            item_to_int[item] = len(item_to_int)\n",
    "\n",
    "print(item_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0    1    2    3    4    5    6    7    8    9    ...  139   \n",
      "ticket_number                                                    ...        \n",
      "150040           1    1    0    0    0    0    0    0    0    0  ...    0  \\\n",
      "150041           0    1    1    0    0    0    0    0    0    0  ...    0   \n",
      "150042           0    0    0    1    0    0    0    0    0    0  ...    0   \n",
      "150043           1    0    0    0    1    0    0    0    0    0  ...    0   \n",
      "150044           0    0    0    0    0    1    0    0    0    0  ...    0   \n",
      "...            ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "288908           0    0    0    0    0    0    0    0    0    0  ...    0   \n",
      "288910           0    0    0    1    0    0    0    0    0    0  ...    0   \n",
      "288911           0    0    0    1    0    0    0    0    1    0  ...    0   \n",
      "288912           0    0    0    1    0    0    0    0    0    0  ...    0   \n",
      "288913           0    0    0    1    0    0    0    0    0    0  ...    0   \n",
      "\n",
      "               140  141  142  143  144  145  146  147  148  \n",
      "ticket_number                                               \n",
      "150040           0    0    0    0    0    0    0    0    0  \n",
      "150041           0    0    0    0    0    0    0    0    0  \n",
      "150042           0    0    0    0    0    0    0    0    0  \n",
      "150043           0    0    0    0    0    0    0    0    0  \n",
      "150044           0    0    0    0    0    0    0    0    0  \n",
      "...            ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "288908           0    0    0    0    0    0    0    0    0  \n",
      "288910           0    0    0    0    0    0    0    0    0  \n",
      "288911           0    0    0    0    0    0    0    0    0  \n",
      "288912           0    0    0    0    0    0    0    0    0  \n",
      "288913           0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[136451 rows x 149 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the transactions to a one-hot encoded format\n",
    "one_hot_encoded = pd.DataFrame(0, index=transactions.index, columns=item_to_int.values())\n",
    "for i, transaction in enumerate(transactions):\n",
    "    for item in transaction:\n",
    "        one_hot_encoded.at[transactions.index[i], item_to_int[item]] = 1\n",
    "\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Applications\\Python\\Python39\\lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     support itemsets\n",
      "0   0.111930      (0)\n",
      "1   0.077163      (1)\n",
      "2   0.494940      (3)\n",
      "3   0.083884      (4)\n",
      "4   0.110714      (5)\n",
      "5   0.037977      (7)\n",
      "6   0.142351      (8)\n",
      "7   0.036277     (18)\n",
      "8   0.030634     (47)\n",
      "9   0.030817   (1, 3)\n",
      "10  0.039531   (1, 4)\n",
      "11  0.036108   (3, 4)\n",
      "12  0.044822   (8, 3)\n"
     ]
    }
   ],
   "source": [
    "# Apply the Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(one_hot_encoded, min_support=0.03, use_colnames=True)\n",
    "\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  antecedents consequents  antecedent support  consequent support   support   \n",
      "0         (1)         (3)            0.077163            0.494940  0.030817  \\\n",
      "1         (1)         (4)            0.077163            0.083884  0.039531   \n",
      "2         (4)         (1)            0.083884            0.077163  0.039531   \n",
      "3         (4)         (3)            0.083884            0.494940  0.036108   \n",
      "4         (8)         (3)            0.142351            0.494940  0.044822   \n",
      "\n",
      "   confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0    0.399373  0.806913 -0.007374    0.840889      -0.205908  \n",
      "1    0.512299  6.107265  0.033058    1.878440       0.906185  \n",
      "2    0.471256  6.107265  0.033058    1.745339       0.912832  \n",
      "3    0.430456  0.869714 -0.005409    0.886780      -0.140539  \n",
      "4    0.314868  0.636175 -0.025633    0.737173      -0.400054  \n"
     ]
    }
   ],
   "source": [
    "# Generate association rules from the frequent itemsets\n",
    "association_rules_df = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.3)\n",
    "\n",
    "print(association_rules_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'baguette', 1: 'pain au chocolat', 2: 'pain', 3: 'traditional baguette', 4: 'croissant', 5: 'banette', 6: 'banettine', 7: 'special bread', 8: 'coupe', 9: 'sand jb emmental', 10: 'kouign amann', 11: 'boule 200g', 12: 'boule 400g', 13: 'gal frangipane 6p', 14: 'campagne', 15: 'moisson', 16: 'cafe ou eau', 17: 'brioche', 18: 'cereal baguette', 19: 'seigle', 20: 'complet', 21: 'divers patisserie', 22: 'gal frangipane 4p', 23: 'cookie', 24: 'ficelle', 25: 'pain aux raisins', 26: 'gal pomme 6p', 27: 'gal pomme 4p', 28: 'financier x5', 29: 'vik bread', 30: 'divers viennoiserie', 31: 'gache', 32: 'sandwich complet', 33: 'pain banette', 34: 'grand far breton', 35: 'quim bread', 36: 'special bread kg', 37: 'gd kouign amann', 38: 'boule polka', 39: 'demi baguette', 40: 'chausson aux pommes', 41: 'baguette graine', 42: 'divers confiserie', 43: 'sucette', 44: 'divers boulangerie', 45: 'boisson 33cl', 46: 'pates', 47: 'formule sandwich', 48: 'divers sandwichs', 49: 'croissant amandes', 50: 'pain choco amandes', 51: 'sachet viennoiserie', 52: 'nantais', 53: 'chocolat', 54: 'pain ssel', 55: 'fondant chocolat', 56: 'gal poire choco 6p', 57: 'gal poire choco 4p', 58: 'galette 8 pers', 59: 'sand jb', 60: 'sachet de crouton', 61: 'grande sucette', 62: 'demi pain', 63: 'tartelette', 64: 'flan', 65: 'paris brest', 66: 'savarin', 67: 'flan abricot', 68: 'baguette apero', 69: 'milles feuilles', 70: 'chou chantilly', 71: 'eclair', 72: 'royal 4p', 73: 'tarte fruits 6p', 74: 'tarte fruits 4p', 75: 'noix japonaise', 76: 'the', 77: 'briochette', 78: 'royal 6p', 79: 'eclair fraise pistache', 80: '', 81: 'gd far breton', 82: 'triangles', 83: 'tropezienne', 84: 'tropezienne framboise', 85: 'royal', 86: 'tarte fraise 6p', 87: 'tartelette fraise', 88: 'tarte fraise 4per', 89: 'fraisier', 90: 'nid de poule', 91: 'tartelette choc', 92: 'pain de mie', 93: 'crumble', 94: 'financier', 95: 'divers boissons', 96: 'cake', 97: 'viennoise', 98: 'traiteur', 99: 'pain graines', 100: 'platprepare650', 101: 'platprepare550', 102: 'platprepare700', 103: 'formule plat prepare', 104: 'st honore', 105: 'brownies', 106: 'religieuse', 107: 'platprepare600', 108: 'delicetropical', 109: 'crumblecaramel ou pistae', 110: 'pt nantais', 111: 'gd nantais', 112: 'douceur d hiver', 113: 'trois chocolat', 114: 'article 295', 115: 'tarte fine', 116: 'entremets', 117: 'brioche de noel', 118: 'framboisier', 119: 'buche 4pers', 120: 'buche 6pers', 121: 'gd plateau sale', 122: 'buche 8pers', 123: 'pt plateau sale', 124: 'reduction sucrees 12', 125: 'pain noir', 126: 'reduction sucrees 24', 127: 'bottereau', 128: 'meringue', 129: 'palmier', 130: 'paille', 131: 'plat 650e', 132: 'plat 760e', 133: 'plat 700', 134: 'plat', 135: 'plat 830e', 136: 'formule pate', 137: 'guerandais', 138: 'palet breton', 139: 'caramel noix', 140: 'macaron', 141: '12 macaron', 142: 'armoricain', 143: 'plaque tarte 25p', 144: 'sable f  p', 145: 'pain suisse pepito', 146: 'tulipe', 147: 'tartelette cocktail', 148: 'sachet de viennoiserie'}\n"
     ]
    }
   ],
   "source": [
    "# Invert the item_to_int dictionary to create a new dictionary for mapping integer identifiers to item names\n",
    "int_to_item = {v: k for k, v in item_to_int.items()}\n",
    "\n",
    "print(int_to_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the integer identifiers in association_rules_df back to item names\n",
    "association_rules_df['antecedents'] = association_rules_df['antecedents'].apply(lambda x: frozenset([int_to_item[i] for i in x]))\n",
    "association_rules_df['consequents'] = association_rules_df['consequents'].apply(lambda x: frozenset([int_to_item[i] for i in x]))\n",
    "association_rules_df = association_rules_df.sort_values(by='support', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          antecedents             consequents  antecedent support  consequent support   support  confidence      lift  leverage  conviction  zhangs_metric\n",
      "4             (coupe)  (traditional baguette)            0.142351            0.494940  0.044822    0.314868  0.636175 -0.025633    0.737173      -0.400054\n",
      "1  (pain au chocolat)             (croissant)            0.077163            0.083884  0.039531    0.512299  6.107265  0.033058    1.878440       0.906185\n",
      "2         (croissant)      (pain au chocolat)            0.083884            0.077163  0.039531    0.471256  6.107265  0.033058    1.745339       0.912832\n",
      "3         (croissant)  (traditional baguette)            0.083884            0.494940  0.036108    0.430456  0.869714 -0.005409    0.886780      -0.140539\n",
      "0  (pain au chocolat)  (traditional baguette)            0.077163            0.494940  0.030817    0.399373  0.806913 -0.007374    0.840889      -0.205908\n"
     ]
    }
   ],
   "source": [
    "# Set pandas options to display complete contents of columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Print the updated association rules with item names\n",
    "print(association_rules_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
