{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m tokenizer\n\u001b[0;32m      5\u001b[0m \u001b[39m# import dataset \u001b[39;00m\n\u001b[0;32m      6\u001b[0m dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../resume_dataset/resume_dataset.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# import dataset \n",
    "dataset = pd.read_csv('../dataset/resume_dataset.csv')\n",
    "\n",
    "# drop unecessary columns\n",
    "dataset = dataset.drop(columns=['ID', 'Resume_html', 'Category'])\n",
    "\n",
    "# set settings for printing\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "print(dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Resume_str]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# check for missing values in each row\n",
    "missing_values_per_row = dataset.isnull().any(axis=1)\n",
    "\n",
    "# display rows with missing values\n",
    "rows_with_missing_values = dataset[missing_values_per_row]\n",
    "print(rows_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "['HR ADMINISTRATOR/MARKETING ASSOCIATE']\n",
      "['HR ADMINISTRATOR']\n",
      "['Summary']\n",
      "['Dedicated Customer Service Manager with 15+ years of experience in Hospitality and Customer Service Management.']\n",
      "['Respected builder and leader of customer-focused teams; strives to instill a shared, enthusiastic commitment to customer service.']\n",
      "['Highlights']\n",
      "['Focused on customer satisfaction']\n",
      "['Team management']\n",
      "['Marketing savvy']\n"
     ]
    }
   ],
   "source": [
    "segmented_sentence_dataset = []\n",
    "\n",
    "# iterate over all resumes\n",
    "for resume in dataset['Resume_str']:\n",
    "   # split the text when there is two or more spaces between\n",
    "   segmented_sentence_dataset += (re.split(r'\\s\\s+', resume))\n",
    "\n",
    "for sentence in segmented_sentence_dataset[:10]:\n",
    "   print([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentence_dataset = []\n",
    "\n",
    "for sentence in segmented_sentence_dataset:\n",
    "    # convert item names to lowercase\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # substitute year to [YEAR] token\n",
    "    sentence = re.sub(r\"(20\\d\\d|19\\d\\d)\", '[YEAR]', sentence)\n",
    "\n",
    "    # substitute numbers to [NUMBER] token\n",
    "    sentence = re.sub(r\"\\d+\\.?\\d*\\+?\", '[NUMBER]', sentence)\n",
    "    \n",
    "    # remove special characters (e.g., punctuations)\n",
    "    special_characters = r\"[!\\\"#$%&()*+,/:;<=>?@^_{|}~•·]\"\n",
    "    sentence = re.sub(special_characters, ' ', sentence)\n",
    "    new_sentence = []\n",
    "    for word in sentence.split(' '):\n",
    "        if (re.search(r\"[\\.\\-]\", word)):\n",
    "            # handler of abbreviations that use '.' (e.g., B.S.)\n",
    "            if (re.search(r\"^[^\\.]+\\.$|^.$\", word)):\n",
    "                word = re.sub(r\"\\.\", ' ', word)\n",
    "            # handler of misplaced '-' and avoid removing '-' for hypenated words (e.g., Mother-in-law)\n",
    "            if (re.search(r\"[^\\s]+-[^\\s]+\", word) == None):\n",
    "                word = re.sub(r\"-\", ' ', word)\n",
    "        new_sentence.append(word)\n",
    "    sentence = ' '.join(new_sentence)\n",
    "\n",
    "    # remove white spaces\n",
    "    sentence = ' '.join(sentence.split())\n",
    "\n",
    "    # explicit removal of observed noise words\n",
    "    noise_words = ['n a', 'company name']\n",
    "    if (sentence in noise_words):\n",
    "        sentence = ''\n",
    "\n",
    "    cleaned_sentence_dataset.append(sentence)\n",
    "\n",
    "# for sentence in cleaned_sentence_dataset[:10]:\n",
    "#    print([sentence])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hr administrator marketing associate']\n",
      "['hr administrator']\n",
      "['dedicated customer service manager with [NUMBER] years of experience in hospitality and customer service management']\n",
      "['respected builder and leader of customer-focused teams strives to instill a shared enthusiastic commitment to customer service']\n",
      "['focused on customer satisfaction']\n",
      "['team management']\n",
      "['marketing savvy']\n",
      "['conflict resolution techniques']\n",
      "['training and development']\n",
      "['skilled multi-tasker']\n"
     ]
    }
   ],
   "source": [
    "sentence_dataset = []\n",
    "\n",
    "# remove data with less than 2 words\n",
    "for sentence in cleaned_sentence_dataset:\n",
    "    if (sentence.strip() != '' \n",
    "            and len(sentence.split(' ')) > 1\n",
    "            and not re.search(r\"\\[YEAR\\]\", sentence)):\n",
    "        sentence_dataset.append(sentence)\n",
    "\n",
    "for sentence in sentence_dataset[:10]:\n",
    "   print([sentence])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
